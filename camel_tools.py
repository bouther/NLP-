# -*- coding: utf-8 -*-
"""Camel-tools

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_ZdnOMagIKkYQn2drtG9dMRvsZpOE9Ep
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/My Drive/camel_tools"

import os
os.environ['CAMELTOOLS_DATA']="/content/drive/My Drive/camel_tools/camel_tools"

import re
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import camel_tools
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import string
from nltk.stem import WordNetLemmatizer
from wordcloud import WordCloud
nltk.download('wordnet')
nltk.download("punkt")
nltk.download("stopwords")

from camel_tools.sentiment import SentimentAnalyzer

sa = SentimentAnalyzer.pretrained()

# Predict the sentiment of a single sentence
sentiment = sa.predict_sentence('أنا بخير')

# Predict the sentiment of multiple sentences
sentences = [
    'أنا بخير',
    'أنا لست بخير',"لا أعرف"
]
sentiments = sa.predict(sentences)

sentiments

from camel_tools.ner import NERecognizer

ner = NERecognizer.pretrained()

# Predict the labels of a single sentence.
# The sentence must be pretokenized by whitespace and punctuation.
sentence = 'إمارة أبوظبي هي إحدى إمارات دولة الإمارات العربية المتحدة السبع .'.split()
labels = ner.predict_sentence(sentence)

# Print the list of token-label pairs
print(list(zip(sentence, labels)))

df=pd.read_csv("https://um6p-datascience.s3.eu-west-3.amazonaws.com/datasets/hespress/hespress_comments_en.csv")

print(df.shape)
df.sample(5)

df.topic.value_counts()

"""# Preprocessing

## For english text
####1-Load the raw text.
####2-Split into tokens.
####3-Convert to lowercase.
####4-Remove punctuation from each token.
####5-Filter out remaining tokens that are not alphabetic.
####6-Filter out tokens that are stop words.
"""

#Tokenize

english_tokens=df["en"].apply(lambda text : word_tokenize(str(text)))

# convert to lower case

english_tokens = english_tokens.apply(lambda token : [w.lower() for w in token])

# remove remaining tokens that are not alphabetic

english_tokens = english_tokens.apply(lambda token : [word for word in token if word.isalpha()])

# filter out stop words

from nltk.corpus import stopwords
stop_words = set(stopwords.words('english'))
english_tokens = english_tokens.apply(lambda token : [w for w in token if not w in stop_words])

# Lemmatization 

lemmatizer = WordNetLemmatizer()

english_tokens= english_tokens.apply(lambda token : [ lemmatizer.lemmatize(w) for w in token])

text_en=[]
for token in english_tokens :

  text_en.append(" ".join(token))

text_en[:5]

wordcloud = WordCloud()
wordcloud.generate("".join(text_en))

# Display the generated image:
# the matplotlib way:
plt.subplots(1,1, figsize = (9,9))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")

"""## For arabic text"""

# Arabic stopwords 

stopwords = open('/content/list.txt', 'r').read()
stopwords=stopwords.split("\n")
stopwords[:10]

# Remove punctuation
remove = '"#$%&()*+/:;<=>@[\\]^_`{|}~.!?”“'
pattern = r"[{}]".format(remove)
df.comment = df.comment.apply(lambda text : re.sub(pattern,' ', str(text)) )

# Tokenization 
import camel_tools.tokenizers.word
arabic_tokens= df.comment.apply(lambda text : camel_tools.tokenizers.word.simple_word_tokenize(str(text)))

# Remove stopwords 

stopwords = open('/content/list.txt', 'r').read()
stopwords=stopwords.split("\n")

arabic_tokens = arabic_tokens.apply(lambda token : [w for w in token if not w in stopwords])

arabic_tokens[:5]

# Lemmatization 

from nltk.stem.isri import ISRIStemmer
st = ISRIStemmer()
arabic_tokens = arabic_tokens.apply(lambda token : [st.stem(w) for w in token])

text_ara=[]
for token in arabic_tokens :

  text_ara.append(" ".join(token))

text_ara[:5]

from ar_wordcloud import ArabicWordCloud
awc = ArabicWordCloud(background_color="black")


wc = awc.from_text(u" ".join(text_ara))
plt.subplots(1,1, figsize = (9,9))
plt.axis("off")
plt.imshow(wc)

"""# Sentiment Analysis comparison 

"""

# Create a variable related to score.

sentiment = ['positive' if score > 0 
                             else 'negative' if score < 0 
                                 else 'neutral' 
                                     for score in df.score]

from textblob import TextBlob
pred_txtb= [TextBlob(txt).sentiment.polarity for txt in text_en ]

# Sentiment predicted by TextBlob
 
sentiment_tb = ['positive' if score > 0 
                             else 'negative' if score < 0 
                                 else 'neutral' 
                                     for score in pred_txtb]

import time

from camel_tools.sentiment import SentimentAnalyzer
tic = time.process_time()

sa = SentimentAnalyzer.pretrained()
pred_ara = sa.predict(text_ara[:1000])

toc = time.process_time()
print ("\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")

from sklearn.metrics import *

print(classification_report(sentiment_tb[:1000], pred_ara))
print(f"Accuracy score de came_tools % à TextBlob :  {accuracy_score(sentiment_tb[:1000], pred_ara)}")
print(f"Accuracy score de TextBlob % à la vraie sentiment :  {accuracy_score(sentiment[:1000], sentiment_tb[:1000])}")
print(f"Accuracy score camel_tools % à la vraie sentiment:  {accuracy_score(sentiment[:1000], pred_ara)}")

